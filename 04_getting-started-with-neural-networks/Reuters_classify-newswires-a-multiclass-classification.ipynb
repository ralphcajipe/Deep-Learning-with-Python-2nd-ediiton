{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying newswires: A multiclass classification example\n",
    "Problem: To classify Reuters newswires into 46 mutually exclusive topics.\n",
    "A single-label multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Reuters dataset\n",
    "- Set of short newswires (electronic news) and their topics, published by Reuters in 1986.\n",
    "- Widely used toy dataset for text classification.\n",
    "- 46 different topics, each topic has at least 10 examples in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the Reuters dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 15:34:12.026860: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-24 15:34:12.026909: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
    "    num_words=10000)\n",
    "# Argument `num_words` Restricts the data to the 10,000 most frequently occuring words found in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have\n",
    "8,982 training examples and\n",
    "2,246 test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "# Printing the length of the train_data\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "# Printing the length of the test_data\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with IMDB reviews dataset, each example is encoded as a list of integers (word indices):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979, 3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]"
     ]
    }
   ],
   "source": [
    "# train_data example at index 10\n",
    "print(train_data[10], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decoding the newswires back to text** <br>\n",
    "To decode it back to words, in case curious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of words and their index.\n",
    "word_index = reuters.get_word_index()\n",
    "\n",
    "# Reversing the key and value of the dictionary.\n",
    "reverse_word_index = dict(\n",
    "    [(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "decoded_newswire = \" \".join(\n",
    "    [reverse_word_index.get(i - 3, \"?\") for i in train_data[0]])\n",
    "# Note that the indices are offset by 3 because 0, 1, and 2 are reserved indices for\n",
    "# \"padding,\" \"start of sequence,\" and \"unknown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# Printing the decoded newswire at index 0   â˜ --> train_data[0]\n",
    "print(decoded_newswire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label associated with an example is an integer between 0 and 45 - a topic index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "<em>Vectorize the data.</em> <br>\n",
    "**Encoding the input data (x)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    \"\"\"Vectorizing the sequence of words.\"\"\"\n",
    "    \n",
    "    # Creates an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j in sequence:\n",
    "            # Sets specific indices of results[i] to 1s\n",
    "            results[i, j] = 1\n",
    "    return results\n",
    "    \n",
    "# Vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "\n",
    "# Vectorized test data\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding the labels (y)**\n",
    "- To vectorize labels, there are two possibilities: cast the label list as an integer tensor or use <em>one-hot encoding</em>.\n",
    "- One-hot encoding is a widely used format for categorical data, also called <em>categorical encoding</em>.\n",
    "- In this case, one-hot encoding of the labels consists of embedding each label as an all-zero vector with a 1 in the place of a specific index. It's like \"ignore the rest as zeros but make a specific label index as 1\" for identification. \n",
    "- The following are two ways to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The explicit or manual way by defining a function\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# def to_one_hot(labels, dimension=46):\n",
    "#    \"\"\"\n",
    "#    Converting the labels into one hot encoding.\n",
    "#    \"\"\"\n",
    "#    results = np.zeros((len(labels), dimension))\n",
    "#    for i, label in enumerate(labels):\n",
    "#        results[i, label] = 1\n",
    "#    return results\n",
    "\n",
    "\n",
    "# Function calls\n",
    "# Vectorized training labels\n",
    "# y_train = to_one_hot(train_labels)\n",
    "\n",
    "# Vectorized test labels\n",
    "# y_test = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The built-in way to do this in Keras:\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building your model\n",
    "ðŸ“•ðŸ’¡ See page 108 for better understanding. <br>\n",
    "\n",
    "**Model definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating your approach\n",
    "Let's set apart 1,000 samples in the training data to use as a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting aside a validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Taking the first 1000 elements of the x_train (input data).\n",
    "x_val = x_train[:1000]\n",
    "\n",
    "# Taking all the elements of the x_train (input data) starting from the 1000th element.\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "#  Taking the first 1000 elements of the y_train (label data).\n",
    "y_val = y_train[:1000]\n",
    "\n",
    "# Taking all the elements of the y_train (label data) starting from the 1000th element.\n",
    "partial_y_train = y_train[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train the model for 20 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 2.5941 - accuracy: 0.5413 - val_loss: 1.6927 - val_accuracy: 0.6600\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.3837 - accuracy: 0.7159 - val_loss: 1.3034 - val_accuracy: 0.7160\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.0480 - accuracy: 0.7735 - val_loss: 1.1415 - val_accuracy: 0.7640\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.8321 - accuracy: 0.8201 - val_loss: 1.0819 - val_accuracy: 0.7620\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.6676 - accuracy: 0.8557 - val_loss: 1.0025 - val_accuracy: 0.7900\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.5389 - accuracy: 0.8847 - val_loss: 0.9769 - val_accuracy: 0.7910\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4352 - accuracy: 0.9073 - val_loss: 0.9354 - val_accuracy: 0.8080\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.3573 - accuracy: 0.9270 - val_loss: 0.9215 - val_accuracy: 0.8130\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2986 - accuracy: 0.9347 - val_loss: 0.8989 - val_accuracy: 0.8170\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.2477 - accuracy: 0.9431 - val_loss: 0.9046 - val_accuracy: 0.8110\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2191 - accuracy: 0.9471 - val_loss: 0.9147 - val_accuracy: 0.8180\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1891 - accuracy: 0.9505 - val_loss: 0.9557 - val_accuracy: 0.8050\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1709 - accuracy: 0.9521 - val_loss: 1.0139 - val_accuracy: 0.8080\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1575 - accuracy: 0.9515 - val_loss: 0.9779 - val_accuracy: 0.8050\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1443 - accuracy: 0.9563 - val_loss: 1.0525 - val_accuracy: 0.7960\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1400 - accuracy: 0.9560 - val_loss: 1.0066 - val_accuracy: 0.8040\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.1269 - accuracy: 0.9557 - val_loss: 1.0264 - val_accuracy: 0.8130\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1238 - accuracy: 0.9578 - val_loss: 1.0574 - val_accuracy: 0.8060\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1170 - accuracy: 0.9573 - val_loss: 1.0668 - val_accuracy: 0.8030\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1124 - accuracy: 0.9580 - val_loss: 1.0672 - val_accuracy: 0.8030\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's display its loss and accuracy curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting the training and validation loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting the training and validation accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model begins to overfit after nine epochs. Let's train a new model from scratch for nine epochs ans then evaluate it on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retraining a model from scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 15:35:39.223348: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 359280000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 21ms/step - loss: 2.5838 - accuracy: 0.5177\n",
      "Epoch 2/9\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1.3571 - accuracy: 0.7159\n",
      "Epoch 3/9\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1.0059 - accuracy: 0.7852\n",
      "Epoch 4/9\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.7882 - accuracy: 0.8367\n",
      "Epoch 5/9\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.6278 - accuracy: 0.8709\n",
      "Epoch 6/9\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4979 - accuracy: 0.8937\n",
      "Epoch 7/9\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4011 - accuracy: 0.9177\n",
      "Epoch 8/9\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.3300 - accuracy: 0.9296\n",
      "Epoch 9/9\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.2748 - accuracy: 0.9377\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.9949 - accuracy: 0.7867\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss = \"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512)\n",
    "\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9949263334274292, 0.7867319583892822]\n",
      "Test loss: 99.49%\n",
      "Test accuracy: 78.67%\n"
     ]
    }
   ],
   "source": [
    "print(results)\n",
    "print(f\"Test loss: {results[0]:.2%}\")\n",
    "print(f\"Test accuracy: {results[1]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach reaches an accuracy of ~79%. With a balanced binary classification problem, the accuracy reached by a purely random classifier is about 50%. But in this case, we have 46 classes, and they may not be equally repreented. What would be the accuracy of a random classifier? We could try quickly implementing one to check this by observing the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1803205699020481"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling the test labels and then comparing the shuffled labels to the original labels. \n",
    "# The mean of the hits array is the accuracy of the model.\n",
    "import copy\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
    "hits_array.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18%\n"
     ]
    }
   ],
   "source": [
    "print(f\"{hits_array.mean():.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a random classifier would score around 18% classification accuracy, so the results of our model seem pretty good compared to the random classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000001"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A different way to handle the labels and the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The importance of having sufficiently large intermediate layers\n",
    "**A model with an information bottleneck (traffic or congestion in learning)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.8198 - accuracy: 0.3814 - val_loss: 2.1434 - val_accuracy: 0.5820\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.7147 - accuracy: 0.6232 - val_loss: 1.5511 - val_accuracy: 0.6300\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.3102 - accuracy: 0.6570 - val_loss: 1.3933 - val_accuracy: 0.6800\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.1341 - accuracy: 0.7350 - val_loss: 1.3362 - val_accuracy: 0.7080\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.0067 - accuracy: 0.7642 - val_loss: 1.2864 - val_accuracy: 0.7190\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.9085 - accuracy: 0.7813 - val_loss: 1.2673 - val_accuracy: 0.7180\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.8303 - accuracy: 0.7949 - val_loss: 1.3027 - val_accuracy: 0.7150\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7681 - accuracy: 0.8018 - val_loss: 1.2874 - val_accuracy: 0.7170\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.7169 - accuracy: 0.8103 - val_loss: 1.3141 - val_accuracy: 0.7180\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6697 - accuracy: 0.8173 - val_loss: 1.3377 - val_accuracy: 0.7130\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.6327 - accuracy: 0.8246 - val_loss: 1.4078 - val_accuracy: 0.7140\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5989 - accuracy: 0.8331 - val_loss: 1.4582 - val_accuracy: 0.7160\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5675 - accuracy: 0.8383 - val_loss: 1.5320 - val_accuracy: 0.7180\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.5408 - accuracy: 0.8443 - val_loss: 1.5200 - val_accuracy: 0.7290\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5172 - accuracy: 0.8497 - val_loss: 1.6395 - val_accuracy: 0.7220\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.4967 - accuracy: 0.8599 - val_loss: 1.7381 - val_accuracy: 0.7170\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.4784 - accuracy: 0.8623 - val_loss: 1.7553 - val_accuracy: 0.7230\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.4656 - accuracy: 0.8668 - val_loss: 1.7841 - val_accuracy: 0.7210\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.4491 - accuracy: 0.8701 - val_loss: 1.8346 - val_accuracy: 0.7210\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.4360 - accuracy: 0.8748 - val_loss: 1.9587 - val_accuracy: 0.7180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8721a9bf70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# We will use a validation set since this is a simulation of having a bottleneck, not our final model.\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model now peaks at ~71% validation accuracy, an 8% absolute drop. This drop is mostly due to the fact that we're trying to compress a lot of information (enough information to recover the separation hyperplanes of 46 classes) into an intermediate space that is too low-dimensional. The model is able to cram <em>most</em> of the necessary information into these four-dimensional representations, but not all of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try using larger or smaller layers: 32 units, 128 units, and so on.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using smaller layers of 32 units**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 2.2024 - accuracy: 0.5494 - val_loss: 1.4933 - val_accuracy: 0.6500\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.2459 - accuracy: 0.7191 - val_loss: 1.2015 - val_accuracy: 0.7080\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.9279 - accuracy: 0.7989 - val_loss: 1.0438 - val_accuracy: 0.7790\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.7194 - accuracy: 0.8438 - val_loss: 0.9870 - val_accuracy: 0.7790\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.5654 - accuracy: 0.8770 - val_loss: 0.9366 - val_accuracy: 0.8020\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.4469 - accuracy: 0.9040 - val_loss: 0.9472 - val_accuracy: 0.7930\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.3565 - accuracy: 0.9222 - val_loss: 0.9323 - val_accuracy: 0.8020\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.2905 - accuracy: 0.9344 - val_loss: 0.9327 - val_accuracy: 0.8210\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.2411 - accuracy: 0.9445 - val_loss: 1.0015 - val_accuracy: 0.8100\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.2103 - accuracy: 0.9485 - val_loss: 1.0167 - val_accuracy: 0.8040\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1831 - accuracy: 0.9519 - val_loss: 1.0086 - val_accuracy: 0.8150\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1652 - accuracy: 0.9528 - val_loss: 1.0380 - val_accuracy: 0.8120\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1510 - accuracy: 0.9543 - val_loss: 1.0463 - val_accuracy: 0.8100\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1423 - accuracy: 0.9562 - val_loss: 1.1157 - val_accuracy: 0.7970\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1349 - accuracy: 0.9562 - val_loss: 1.1615 - val_accuracy: 0.8050\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1310 - accuracy: 0.9558 - val_loss: 1.1680 - val_accuracy: 0.8010\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1228 - accuracy: 0.9583 - val_loss: 1.1908 - val_accuracy: 0.7970\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1207 - accuracy: 0.9589 - val_loss: 1.2379 - val_accuracy: 0.7960\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1176 - accuracy: 0.9568 - val_loss: 1.2834 - val_accuracy: 0.7810\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1158 - accuracy: 0.9555 - val_loss: 1.2210 - val_accuracy: 0.7990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8720fb4f40>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# We will use a validation set since this is a simulation of using 32 units, not our final model.\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model now peaks at ~80% validation accuracy, a 1% increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using larger layers of 128 units**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 2s 19ms/step - loss: 1.5737 - accuracy: 0.6661 - val_loss: 1.0876 - val_accuracy: 0.7690\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.7665 - accuracy: 0.8360 - val_loss: 0.8971 - val_accuracy: 0.8220\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.4574 - accuracy: 0.9024 - val_loss: 0.8375 - val_accuracy: 0.8140\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.3014 - accuracy: 0.9334 - val_loss: 0.8792 - val_accuracy: 0.8120\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.2269 - accuracy: 0.9451 - val_loss: 0.9490 - val_accuracy: 0.8070\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1825 - accuracy: 0.9513 - val_loss: 0.9358 - val_accuracy: 0.8140\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.1756 - accuracy: 0.9524 - val_loss: 0.9639 - val_accuracy: 0.8170\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.1512 - accuracy: 0.9553 - val_loss: 1.1162 - val_accuracy: 0.7990\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.1388 - accuracy: 0.9553 - val_loss: 0.9962 - val_accuracy: 0.8050\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.1292 - accuracy: 0.9574 - val_loss: 1.0253 - val_accuracy: 0.8070\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1244 - accuracy: 0.9535 - val_loss: 1.1092 - val_accuracy: 0.8050\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.1166 - accuracy: 0.9559 - val_loss: 1.2221 - val_accuracy: 0.8030\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.1107 - accuracy: 0.9577 - val_loss: 1.1582 - val_accuracy: 0.8040\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.1064 - accuracy: 0.9582 - val_loss: 1.1460 - val_accuracy: 0.8100\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.0991 - accuracy: 0.9569 - val_loss: 1.2581 - val_accuracy: 0.8070\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0964 - accuracy: 0.9564 - val_loss: 1.2637 - val_accuracy: 0.8010\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.0933 - accuracy: 0.9579 - val_loss: 1.3277 - val_accuracy: 0.8050\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.0893 - accuracy: 0.9572 - val_loss: 1.4036 - val_accuracy: 0.8130\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.0869 - accuracy: 0.9573 - val_loss: 1.5336 - val_accuracy: 0.7900\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.0817 - accuracy: 0.9570 - val_loss: 1.5616 - val_accuracy: 0.8030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8721a9ae90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# We will use a validation set since this is a simulation of using 128 units, not our final model.\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model now peaks at 80% validation accuracy, but a much better increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now try using a single intermediate layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.7993 - accuracy: 0.6322 - val_loss: 1.1928 - val_accuracy: 0.7370\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.9299 - accuracy: 0.8034 - val_loss: 0.9788 - val_accuracy: 0.7980\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.6390 - accuracy: 0.8662 - val_loss: 0.8564 - val_accuracy: 0.8170\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.4549 - accuracy: 0.9053 - val_loss: 0.8207 - val_accuracy: 0.8250\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.3397 - accuracy: 0.9277 - val_loss: 0.8238 - val_accuracy: 0.8210\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.2657 - accuracy: 0.9394 - val_loss: 0.8130 - val_accuracy: 0.8280\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.2178 - accuracy: 0.9460 - val_loss: 0.8237 - val_accuracy: 0.8340\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.1847 - accuracy: 0.9498 - val_loss: 0.8476 - val_accuracy: 0.8280\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1628 - accuracy: 0.9528 - val_loss: 0.8741 - val_accuracy: 0.8250\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1487 - accuracy: 0.9550 - val_loss: 0.9179 - val_accuracy: 0.8150\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1360 - accuracy: 0.9559 - val_loss: 0.9363 - val_accuracy: 0.8130\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1292 - accuracy: 0.9564 - val_loss: 0.9350 - val_accuracy: 0.8190\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1213 - accuracy: 0.9550 - val_loss: 0.9966 - val_accuracy: 0.8090\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.1171 - accuracy: 0.9562 - val_loss: 1.0347 - val_accuracy: 0.8090\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.1154 - accuracy: 0.9575 - val_loss: 1.0359 - val_accuracy: 0.8070\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1101 - accuracy: 0.9579 - val_loss: 1.0446 - val_accuracy: 0.8120\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1086 - accuracy: 0.9562 - val_loss: 1.0860 - val_accuracy: 0.8060\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1055 - accuracy: 0.9582 - val_loss: 1.1468 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1038 - accuracy: 0.9585 - val_loss: 1.1385 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1042 - accuracy: 0.9560 - val_loss: 1.1278 - val_accuracy: 0.8030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f870c150c40>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# We will use a validation set since this is a simulation of using \n",
    "# one intermediate layer, not our final model.\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model still peaks at 80% validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read **Wrapping Up** on page 113."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f946df053fbf2b937619d3c5458e7af74262f9a954d8797ba0b27400bcafe06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
